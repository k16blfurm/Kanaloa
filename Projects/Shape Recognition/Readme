Image Classifier Documentation

Link to our multi classifier with color recognition:
https://www.pyimagesearch.com/2018/05/07/multi-label-classification-with-keras/

This site contains the code for the classifier that we are using as well as a thorough explanation of the code from the creator.

Originally:  This classifier categorized clothing and it’s color

Note:  Originally (when we first tested out the classifier with the clothing data) it was thought that the image training data was used because the accuracy was so high; however, this was not the case.  We actually tested it out with clothing images that were not within the training dataset.

To run the classifier (on Windows):
Enter command prompt
Then type: conda activate tfdeeplearning
This lets us run the classifier in Raymond’s environment that he created with his config file.
In order to use Raymond’s environment, follow his instructions on the Kanaloa Github under the Deep Learning Project Directory.
Link:  https://github.com/riplaboratory/Kanaloa/tree/master/Projects/DeepLearning

Execute classifier by running the command:
python train.py --dataset dataset --model fashion.model \
	--labelbin mlb.pickle

In order to run this classifier, you need to install additional libraries that are missing in the anaconda environment that Raymond created with his config file.
These include: keras, imutils, and cv2
To install:  Enter the tfdeeplearning environment using the command given earlier, and type:
pip install keras
pip install imutils
pip install opencv-python

We then replaced the clothing training images with a shape dataset from Kaggle:
https://www.kaggle.com/smeschke/four-shapes
This shape dataset contains 4 images: Circle, Square, Star, and Triangle
We threw each shape into separate folders and named them:
Circle_black
Square_black
Star_black
Triangle_black

This classifier automatically generates labels based on the names of the folders of the image data that we create.  It’s important to name the folders in this format, or else the classifier will not run and will be stuck in the training phase.

Here is a screenshot of retraining the classifier with shapes:


Training will take a while as this will loop 75 times (75 Epochs), although the number of Epochs can be adjusted to be less (although this will significantly reduce accuracy).

Results:
To test out the classifier, enter in this command:
python classify.py --model fashion.model --labelbin mlb.pickle \
	--image examples/example_01.jpg
Replace the “examples/example_01.jpg” with the path to whatever image you want to feed in.
For example, if we want to feed in an image called circle_01.jpg within the “examples” folder, we would use:
	--image examples/circle_01.jpg

Note: If the classifier does not work at first, simply restart the classifier if this happens and it should work again.

Here are some screenshots of the output result of random images that we have fed in (all of which are failures because they use terrible image data):







Here are the results of images that we have fed in from a slightly better dataset of random images that yield better results:













**As of right now, we tested this classifier on things that it wasn’t trained for since we had trained it on a dataset from Kaggle with only solid black squares, circles, triangles, and stars.

Important Note:  This classifier must be trained on to recognize each shape and color.  So, in this case we have only trained it to recognize the color black since that is the color of all of our shapes within this test data set.  However, if we feed it in an image of a shape of a different color, the classifier doesn’t know what to do and it ends up classifying an image as the wrong color and shape.  This most likely is due to the fact that we did not train it to recognize multiple colors, which causes it to become confused.  When the image contains a white background, and a shape and color that the classifier is trained on, it works fine.  However, once an image is fed in with color in the background, the classifier becomes completely wrong and gets confused.  If we use a much better dataset that is more related to the actual images that we will need to classify, the classifier program should perform as expected (although we have yet to prove this since we need better image data).
In the case of the example image dataset with the clothing, each image contained multiple colors and even people with a white background, with the focal point being the clothing and its color.  However, it was accurate.  Our dataset that we used seems too simple given that each image only contains one shape in a solid black color with a blank white background.  This is most likely the reason why the classifier is currently not performing as expected when feeding it in a random image of a colored shape, and why it gets both the color and the shape completely wrong.

Image Data Collection:
Here is how we got image data online through google images (via breaking the google terms of service):
https://github.com/hardikvasa/google-images-download
This Github repository lists the complete instructions to download and scrape images off of google images using the Windows terminal command line.
Important Note:
You need to specify which directory you want to save the pictures to by typing: -o /[whatever directory you want to save the images to] at the end (-o is output directory)
If you don’t do this, finding where the images downloaded to will be a pain.
You can even choose which format to save the images as (i.e. jpg, png, etc.), and specify how many images you want to download (the number right before the -o).
Here is a screenshot of the code to run in terminal to scrape images:

In this screenshot, we scraped images of polar bears, balloons, and beaches.  This will obviously be replaced by the topic of whatever images you want to scrape (in this case, red squares, blue triangles, yellow circles, etc.)

We downloaded about 1000 images of each possible shape and color to use as (poor quality) testing data (for now) until we get ahold of a better and more accurate dataset that is similar to what we need.
This dataset contains about 16000 images which includes:
1000 red circles
1000 red squares
1000 red triangles
1000 red crosses
1000 green circles
1000 green squares
1000 green triangles
1000 green crosses
1000 blue circles
1000 blue squares
1000 blue triangles
1000 blue crosses
1000 yellow circles
1000 yellow squares
1000 yellow triangles
1000 yellow crosses

Note: This dataset is not a well controlled set, as we scraped off these images from google images using the command line to get as much data as possible.  So, this data will not yield accurate results with this classifier, especially since our classifier was not trained on this particular dataset as mentioned earlier.  Once we get ahold of a much better dataset, we will be able to have a much better idea of how this classifier truly performs.

Alternative to data collection:  We are considering using a Raspberry Pie to crawl around the web and collect approximately 10000 images of shapes to make data collection easier for us.  It sounds ridiculous, but it might actually work.

**We have uploaded the classifier code, the model, and the black shapes dataset that we have used to initially retrain the classifier model to the Kanaloa Team drive under the image recognition folder.

**We have also uploaded the classifier code to GitHub
